
# gradianudenisa.data_projects
#__Project 1: Hacker News__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Hacker%20News)<br>
In this project we are analyzing a dataset of submissions to the Hacker News site, which is a site where posts receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result. In this context we are interested to know the following:


* Do Ask HN (meaning users submiting a post to ask the Hacker News community a question) or Show HN (meaning users submiting a post to show the Hacker News community a project, product etc.) receive more comments on average?
* Do posts created at a certain time receive more comments on average

#__Project 2: Exploring Car Sales Data__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Exploring%20Car%20Sales)<br>
The goal of this project is to use and apply various data cleaning techniques to:
* transform numeric data stored as text which should be cleaned and converted, 
* removing outliers, 
* dealing with incorrect data, 
* mapping german words to their english counterparts etc.<br><br>
and to analyze and explore the included used car listings, namely:<br><br>
* exploring variations of price across different car brands, 
* exploring average mileage for top 6 cars (by price) and see if there's any visible link with mean price, 
* finding the most common brand/model combinations, 
* finding how much cheaper are cars with damage than their non-damaged counterparts etc.

#__Project 3: Heavy Traffic Indicators__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Heavy%20Traffic%20Indicators)<br>
Our analysis goal is to determine indicators of heavy traffic on I-94. After processing the data, we are going to use various exploratory data visualziation techniques (like vsualizing time series data with line plots, visualizing correlations with scatter plots, visulizing frequency distributions with bar plots and histograms, comparing graphs using grid charts) to investigate data and find patterns.<br><br>
After a rigorous examination, we managed to find two types of indicators of heavy traffic on I-94:

__Time indicators__
* The traffic is usually heavier during warm months compared to cold months.
* The traffic is usually heavier on business days compared to the weekends.
* On business days, the rush hours are around 7 and 16.
__Weather indicators__
* Shower snow
* Light rain and snow
* Proximity thunderstorm with drizzle

#__Project 4: Wine Quality Indicators__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Wine%20Quality%20(Matplotlib%20styles))<br>
Our goal in this project is to use Matplotlib's pre-defined style, namely the fivethirtyeight style to build a graph that shows which attributes have the strongest correlation with the wine quality. We will maximize the data-ink ratio and add various structural elements on top of the fivethirtyeight style.

#__Project 5: Analyzing Exchange Rates__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Exchange%20Rates)<br>
The objective of this project is to highlight and use various explanatory data visualization techniques:
* using information design principles (familiarity and maximizing the data-ink ratio) to create better graphs for the targeted audience;
* creating storytelling data visualizations using Matplotlib;
* guiding the audience's attention with pre-attentive attributes;
* creating visual patterns using Gestalt principles.

We will create a storytelling data visualization showing comparatively how the euro-dollar rate changed under the last three US presidents (George W. Bush (2001-2009), Barack Obama (2009-2017), and Donald Trump (2017-2021))

#__Project 6: Analyzing Exit Surveys__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Exit%20Surveys)<br>
Our goal in this project is to use various data cleaning techniques to make the data ready to be analyzed, so that we can extract valuable insights from it. 
After cleaning and transforming the data to be ready for analysis we want to answer the following:
* Are employees who only worked for the institutes for a short period of time resigning due to some kind of dissatisfaction? What about employees who have been there longer?
* Are younger employees resigning due to some kind of dissatisfaction? What about older employees?

#__Project 7: StarWars Surveys__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20StarWars%20Survey)<br>
The purpose of our analysis is to find out if the original movies are ranked higher overall and enjoy more popularity among the fans of the Star Wars series compared to the more recent movies.<br><br> The dataset is based on a survey that implied Star Wars fans (for some questions, the respondent had to check one or more boxes). This type of data is difficult to represent in a column, so before analyzing it the dataset needs some cleaning (mapping).

#__Project 8: Analyzing Factbook data SQL__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Factbook%20Data%20SQL)<br>
In this project, we'll work with data from the CIA World Factbook (the SQLite factbook.db database), a compendium of statistics about all of the countries on Earth. The object of this project is to explore the database using SQL and the Jupyter Notebook interface, filtering the data accordingly to the purpose of our analysis and finding densely populated countries.

#__Project 9: Answering Business Questions using SQL__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Business%20Questions%20SQL)<br>
In this project we will put our SQL skills to work to answer some business questions like:
* which genre sold the most tracks in USA;
* which sales agents sold the most tracks;
* what percentage of purchases are individual tracks vs whole albums.

#__Project 10: Analyzing Stack Exchange__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Analyzing%20Stack%20Exchange)<br>
The aim of the following analysis is to use Data Science Stack Exchange to determine what content should a data science education company create, based on the interest by subject. In order to find what is best content to write about we will use two popularity proxies: for each tag we'll count how many times the tag was used, and how many times a question with that tag was viewed. <br><br>
The analysis contains visualisations for the most used and most viewed tags as well as additional investigation for deep-learning where we tried to establish if the interest was just momentary or if based on a longer term analysis we can conclude the domain has the potential to remain of interest in the future.

#__Project 11: Analyzing Fandango Movie Ratings__ <br>
[Click here to redirect to code](https://github.com/gradianudenisa/gradianudenisa.data_projects/tree/main/Project%20Fandango%20Movie%20Ratings)<br>
The context of this project is based on the work of a data journalist, Walt Hickey, who in October 2015 analyzed movie ratings data and found evidence to suggest that Fandango's rating system was biased and dishonest (discrepancy between the number of stars displayed to users and the actual rating which was almost always rounded up). In this project, we'll analyze more recent movie ratings data to determine whether there has been any change in Fandango's rating system after the analysis that we just mentioned above. <br><br>
The analysis will contain a high-level comparison between the shapes of the distributions using kernel density plots and a more granular analysis using some summary statistics to determine the direction of the change.

This repository is a collection of my guided projects from Dataquest.io. 

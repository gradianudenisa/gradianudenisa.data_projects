{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fd951f",
   "metadata": {},
   "source": [
    "### Project - Building a Spam Filter (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8732e93",
   "metadata": {},
   "source": [
    "In this project we're going to use the multionomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans to build a spam filter for SMS messages. The outline of our work consists in:\n",
    "* teach the computer how humans classify messages\n",
    "* the computer uses that human knowledge to estimate probabilities for new messages — probabilities for spam and non-spam\n",
    "* finally the computer classifies a new message based on these probability values — if the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, then we may need a human to classify the message).<br>\n",
    "\n",
    "The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377db5e3",
   "metadata": {},
   "source": [
    "![Image](https://images.unsplash.com/photo-1557200134-90327ee9fafa?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1740&q=80)\n",
    "_Photo by Stephen Phillips - Hostreviews.co.uk on Unsplash_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b0f6a",
   "metadata": {},
   "source": [
    "### Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6734cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7787c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam=pd.read_csv(\"C:/Users/Denisa/Desktop/Project Apps/project 15/SMSSpamCollection\",sep='\\t',header=None, names=['Label', 'SMS'])\n",
    "sms_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17290a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb258b7",
   "metadata": {},
   "source": [
    "Finding what percentage of the messages is spam and what percentage is ham (\"ham\" means non-spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c39663f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba7d65",
   "metadata": {},
   "source": [
    "### Training and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d840b6",
   "metadata": {},
   "source": [
    "To test the spam filter, we're first going to split our dataset into two categories:\n",
    "* A training set, which we'll use to \"train\" the computer how to classify messages (about 80% of the dataset)\n",
    "* A test set, which we'll use to test how good the spam filter is with classifying new messages (about 20% of the dataset)<br>\n",
    "\n",
    "We are going to design the test set before creating the spam filter to make sure we don't come up with a biased test. We are going to use the messages from the test set as new and have the spam filter classify them to see how accurate the spam filter is.Our goal is to have a spam filter with an accuracy greater than 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8548104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "data_randomized = sms_spam.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.8)\n",
    "\n",
    "# Training/Test split\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5f4c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.54105\n",
       "spam    13.45895\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43fe5ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.804309\n",
       "spam    13.195691\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2cd54a",
   "metadata": {},
   "source": [
    "The percentages of spam and ham in both the training and the test set are similar to what we have in the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a063ec28",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0bc4e",
   "metadata": {},
   "source": [
    "### Letter Case and Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993e2e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove all the punctuation from the SMS column\n",
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ',regex=True)\n",
    "#For each message, transform every letter in every word to lower case\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254bcea",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af656f1",
   "metadata": {},
   "source": [
    "We will create a vocabulary for the messages in the training set. We begin by transforming each message from the SMS column into a list by splitting the string at the space character. We will initiate an empty list named vocabulary, iterate over the SMS column and using a nested loop iterate each message in the SMS column and append each string (word) to the vocabulary list if it doesn't exist already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b4d7a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85de22f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f8694",
   "metadata": {},
   "source": [
    "### The Final Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1128298",
   "metadata": {},
   "source": [
    "To create the dictionary we need for our training set (that we will then convert to a DataFrame) we start by initializing a dictionary named word_counts_per_sms, where each key is a unique word from the vocabulary, and each value is a list of the length of training set, where each element in the list is a 0. We loop over training_set['SMS'] using at the same time the enumerate() function to get both the index and the SMS message (index and sms). Using a nested loop, we loop over sms and we incremenent word_counts_per_sms[word][index] by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41b06986",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b00b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>are</th>\n",
       "      <th>you</th>\n",
       "      <th>going</th>\n",
       "      <th>...</th>\n",
       "      <th>beauty</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   yep  by  the  pretty  sculpture  yes  princess  are  you  going  ...  \\\n",
       "0    1   1    1       1          1    0         0    0    0      0  ...   \n",
       "1    0   0    0       0          0    1         1    1    1      1  ...   \n",
       "2    0   0    0       0          0    0         0    0    0      0  ...   \n",
       "3    0   0    0       0          0    0         0    0    0      0  ...   \n",
       "4    0   0    0       0          0    0         0    0    0      0  ...   \n",
       "\n",
       "   beauty  hides  secrets  n8  jewelry  related  trade  arul  bx526  wherre  \n",
       "0       0      0        0   0        0        0      0     0      0       0  \n",
       "1       0      0        0   0        0        0      0     0      0       0  \n",
       "2       0      0        0   0        0        0      0     0      0       0  \n",
       "3       0      0        0   0        0        0      0     0      0       0  \n",
       "4       0      0        0   0        0        0      0     0      0       0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83bba1",
   "metadata": {},
   "source": [
    "Concatenate the DataFrame above with the DataFrame containing the training set (this way, we'll also have the Label and the SMS columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb42f82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>beauty</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  yep  by  the  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]    1   1    1   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...    0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]    0   0    0   \n",
       "3   ham                                           [havent]    0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0   0    0   \n",
       "\n",
       "   pretty  sculpture  yes  princess  are  ...  beauty  hides  secrets  n8  \\\n",
       "0       1          1    0         0    0  ...       0      0        0   0   \n",
       "1       0          0    1         1    1  ...       0      0        0   0   \n",
       "2       0          0    0         0    0  ...       0      0        0   0   \n",
       "3       0          0    0         0    0  ...       0      0        0   0   \n",
       "4       0          0    0         0    0  ...       0      0        0   0   \n",
       "\n",
       "   jewelry  related  trade  arul  bx526  wherre  \n",
       "0        0        0      0     0      0       0  \n",
       "1        0        0      0     0      0       0  \n",
       "2        0        0      0     0      0       0  \n",
       "3        0        0      0     0      0       0  \n",
       "4        0        0      0     0      0       0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83152e",
   "metadata": {},
   "source": [
    "### Calculating Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84f99d",
   "metadata": {},
   "source": [
    "The Naive Bayes algorithm will need to answer these two probability questions to be able to classify new messages:\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "Also, to calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we'll need to use these equations:\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{aligned}\n",
    "&N_{w_i|Spam} = \\text{the number of times the word } w_i \\text{ occurs in spam messages} \\\\\n",
    "&N_{w_i|Spam^C} = \\text{the number of times the word } w_i \\text{ occurs in non-spam messages} \\\\\n",
    "\\\\\n",
    "&N_{Spam} = \\text{total number of words in spam messages} \\\\\n",
    "&N_{Spam^C} = \\text{total number of words in non-spam messages} \\\\\n",
    "\\\\\n",
    "&N_{Vocabulary} = \\text{total number of words in the vocabulary} \\\\\n",
    "&\\alpha = 1 \\ \\ \\ \\ (\\alpha \\text{ is a smoothing parameter})\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306d48d",
   "metadata": {},
   "source": [
    "Some of the terms in the four equations above will have the same value for every new message. As a start, let's first calculate:\n",
    "* P(Spam) and P(Ham)\n",
    "* NSpam, NHam, NVocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c179455",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Isolating spam and ham messages first\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# N_Ham\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9926a2",
   "metadata": {},
   "source": [
    "### Calculating Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b9374",
   "metadata": {},
   "source": [
    "Next we want to calculate P(wi|Spam) and P(wi|Ham). We will initialize two dictionaries, where each key-value pair is a unique word (from our vocabulary) represented as a string, and the value is 0. Next we will isolate the spam and the ham messages in the training set into two different DataFrames. Finally we will iterate over the vocabulary, and, for each word, calculate P(wi|Spam) and P(wi|Ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()   # spam_messages already defined in a cell above\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum()   # ham_messages already defined in a cell above\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham\n",
    "    \n",
    "ham_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b16a58",
   "metadata": {},
   "source": [
    "### Classifying A New Message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18417464",
   "metadata": {},
   "source": [
    "We have all the constants and parameters we need for the spam filter, which can be understood as a function that:\n",
    "\n",
    "* Takes in as input a new message (w1, w2, ..., wn)\n",
    "* Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "* Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:<br><br>\n",
    "1) If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.<br>\n",
    "2) If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.<br>\n",
    "3) If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb55fb",
   "metadata": {},
   "source": [
    "After erforming a bit of data cleaning on the string message we will iterate over each word in message and for each word, if the word is present in the dictionary containing the spam parameters, then we will update the value of p_spam_given_message by multiplying with the parameter value specific to that word. If the word is present in the dictionary containing \n",
    "the ham parameters, then we will update the value of p_ham_given_message by multiplying with the parameter value specific to that word. Finally we will print a classification label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    #initiate with an initial value\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa96b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c8bfe",
   "metadata": {},
   "source": [
    "### Measuring the Spam Filter's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7da106",
   "metadata": {},
   "source": [
    " We'll now try to determine how well the spam filter does on our test set, given that our algorithm didn't see these 1,114 messages, so every message in the test set is practically new from the perspective of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):    \n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57186bdc",
   "metadata": {},
   "source": [
    "Now we have a function that returns labels instead of printing them, so we can use it to create a new column in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5de1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ef496",
   "metadata": {},
   "source": [
    "Now we can compare the predicted values with the actual values to measure how good our spam filter is with classifying new messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "    \n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a453dd8",
   "metadata": {},
   "source": [
    "The filter had an accuracy of 98.74% on the test set, which is an excellent result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
